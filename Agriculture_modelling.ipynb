{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2a78b90-b069-4841-bd08-f949e586f6fa",
   "metadata": {},
   "source": [
    "## Objective  \n",
    "Identify the single most predictive soil feature for determining the optimal crop.  \n",
    "\n",
    "Using the provided `soil_measures.csv` dataset containing nitrogen (N), phosphorous (P), potassium (K), pH values, and the target crop, this code evaluates each feature individually to find the one that produces the best prediction score for \"crop\".  \n",
    "\n",
    "The result will be stored in a dictionary `best_predictive_feature` where:  \n",
    "- **Key** = best feature name  \n",
    "- **Value** = corresponding evaluation score (based on the chosen metric).  \n",
    "\n",
    "This helps farmers prioritize which soil metric to measure when resources are limited, enabling data-driven decisions to maximize crop yield.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4f12a56-188d-4bde-9efd-2e9442b1bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa3aeba1-9f96-4244-a840-253cd45e9de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crops = pd.read_csv(\"soil_measures.csv\")\n",
    "crops.isna().sum()\n",
    "crops.crop.unique()\n",
    "crops.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb9f4779-051f-458b-980b-8e1148fd4b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = crops.drop(columns=\"crop\"), crops[\"crop\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c2ddf09-3f68-4f0e-8a47-83423d0b17b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for N: 0.1008\n",
      "F1-score for P: 0.0940\n",
      "F1-score for K: 0.1356\n",
      "F1-score for ph: 0.0675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'K': 0.1356131859628798}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_performance = {}\n",
    "for feature in [\"N\", \"P\", \"K\", \"ph\"]:\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train[[feature]])\n",
    "    X_test_scaled = scaler.transform(X_test[[feature]])\n",
    "\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    features_performance[feature] = f1\n",
    "    print(f\"F1-score for {feature}: {f1:.4f}\")\n",
    "\n",
    "best_predictive_feature = {\"K\": features_performance[\"K\"]}\n",
    "best_predictive_feature"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
